# Lunar Lander â€” Double DQN

Train a Deep-Q agent that reliably lands the rocket in Gymnasiumâ€™s **LunarLander-v3** environment. The codebase is short, fully-commented, and runs in real-time on CPUs (M-series Mac, Windows, Linux) or GPUs.

---

## Highlights

| Feature                               | Why it matters                                                            |
| ------------------------------------- | ------------------------------------------------------------------------- |
| **Double DQN update**                 | Reduces Q-value over-estimation â‡’ smoother learning, faster convergence.  |
| **Soft target sync (`Ï„ = 0.005`)**    | Keeps the target network a slow-moving average; stabilises training.      |
| **Replay buffer + Îµ-greedy schedule** | Classic tricks for data efficiency and balanced exploration.              |
| **Early stopping & patience**         | Stops after the 100-episode average â‰¥ 200 _or_ no progress for _N_ evals. |
| **MP4 video recorder**                | Optional `RecordVideo` wrapper saves greedy flights to `./videos/`.       |
| **Tiny MLP (â‰ˆ 11 k params)**          | Fits on low-power laptops; reaches "solved" in â‰ˆ 400â€“800 episodes.        |
| **Seed helper**                       | One call locks RNGs for reproducible curves.                              |

---

## What it accomplishes

- Solves LunarLander (â‰¥â€¯200 avg reward) without GPU.
- Demonstrates how Double DQN differs from vanilla DQN in â‰ˆâ€¯200 lines.
- Serves as a template for any Box2D or Atari taskâ€”swap the env ID and go.

---

## Tech stack

| Package                                         | Purpose                                        | Docs              |
| ----------------------------------------------- | ---------------------------------------------- | ----------------- |
| **[Gymnasium](https://gymnasium.farama.org/)**  | Environments (`LunarLander-v3`, `RecordVideo`) | API, wrappers     |
| **[PyTorch](https://pytorch.org/docs/stable/)** | Neural network & optimiser                     | Tensors, autograd |
| **NumPy**                                       | Fast array math                                | â€”                 |
| **Matplotlib** _(optional)_                     | Rewardâ€‘curve PNG                               | â€”                 |
| **tqdm** _(optional)_                           | Progress bar                                   | â€”                 |
| **Box2DÂ 2.3.10**                                | Physics engine (preâ€‘built arm64 wheels)        | â€”                 |

> **macOS Mâ€‘series note:** use the maintained **`Box2D`** wheel. The legacy `box2dâ€‘py` fails on Pythonâ€¯3.11 arm64.

---

## Further reading and documentation

- **DoubleÂ DQN paper** â€“ _Deep Reinforcement Learning with Double Qâ€‘learning_ (vanÂ HasseltÂ etÂ al.,Â 2016)
- **Gymnasium docs** â€“ <https://gymnasium.farama.org/>
- **PyTorch docs** â€“ <https://pytorch.org/docs/stable/>

---

## Demonstration

[VIDEO IN PROGRESS]

---

## License

MIT â€” fork it, tweak it, land rockets. ðŸš€
